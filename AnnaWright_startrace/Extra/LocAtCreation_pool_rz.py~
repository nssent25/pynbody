'''
Step 2 of stellar halo pipeline
Identifies the host of each star particle in <sim>_tf.npy at the 
time it was formed. Note that what is stored is NOT the amiga.grp 
ID, but the index of that halo in the tangos database. The amiga.grp
ID can be backed out via tangos with sim[stepnum][halonum].finder_id.

Output: <sim>_stardata_<snapshot>.h5
        where <snapshot> is the first snapshot that a given process
        analyzed. There will be <nproc> of these files generated
        and processes will not necessarily analyze adjacent snapshots

Usage:   python LocAtCreation_pool_rz.py <sim> optional:<nproc>
Example: python LocAtCreation_pool_rz.py r634 2

Includes an optional argument to specify number of processes to run
with; default is 4. Note that this will get reduced if you've specified
more processes than you have snapshots to process.

Note that this is currently set up for MMs, but should be easily adapted 
by e.g., changing the paths or adding a path CL argument. 
'''

import numpy as np
import h5py
from astropy.table import Table
from multiprocessing import Pool
import pynbody
import tangos as db
from collections import defaultdict
import sys


import os
base_path = '/home/christenc/Code/python/AnnaWrite_startrace'

for root, dirs, files in os.walk(base_path):
    if root not in sys.path:
        sys.path.append(root)

import FindHaloStars as fhs

def main(simpath, odir, n_processes = 4):
    pynbody.config['halo-class-priority'] = ['AmigaGrpCatalogue']

    # odir = '/Users/Anna/Research/Outputs/M33Analogs/MM/'+cursim+'/'
    # halostarsfile = '/Users/Anna/Research/Outputs/M33Analogs/'+cursim+'_tf.npy'
    # simpath = '/Volumes/Audiobooks/RomZooms/'+cursim+'.romulus25.3072g1HsbBH/'
    cursim = simpath.split('/')[-2]

    fhs.odir = odir
    fhs.simpath = simpath
    fhs.cursim = cursim
    halostarsfile = odir+simpath.split('/')[-2]+'_tf.npy'
    
    dat = np.load(halostarsfile) # load in data
    halostars = dat[0]
    createtime = dat[1]
    #fhs.createtime = createtime
    
    # Grab times for all available snapshots
    tst = [] # name of snapshot
    tgyr = [] # time of snapshot in Gyr
    db_sim = 'snapshots_200crit_' + (simpath.split('/')[-2]).split('.')[0]
    sim = db.get_simulation(db_sim)
    ts = sim.timesteps
    for d in ts:
        tgyr.append(d.time_gyr)
        tst.append(d.extension.split('/')[0])
    tgyr = np.array(tgyr)
    tst = np.array(tst)
    sortord = np.argsort(tgyr)
    tgyr = list(tgyr[sortord])
    tst = list(tst[sortord])

    fhs.tst = tst
    fhs.tgyr = tgyr
    fhs.sim = sim
    
    # which snapshots actually contain new star particles?
    stardist = np.histogram(createtime,bins=[0]+tgyr)
    steplist = np.array(tst)[stardist[0]>0]
    print ('Stars from '+str(len(steplist))+' steps left to deal with')
    np.random.shuffle(steplist) # for load balancing

    nsteps = len(steplist)
    nprocesses = np.min([n_processes,nsteps]) # make sure we have at least as many steps as we have processes
    print ('Initializing ',nprocesses)

    #initialize the process pool and build the chunks to send to each process - adapted from powderday
    p = Pool(processes = nprocesses)
    nchunks = nprocesses
    chunk_start_indices = []
    chunk_start_indices.append(0)

    #this should just be int(nsteps/nchunks) but in case nsteps < nchunks, we need to ensure that this is at least  1
    delta_chunk_indices = np.max([int(nsteps / nchunks),1])

    for n in range(1,nchunks):
        chunk_start_indices.append(chunk_start_indices[n-1]+delta_chunk_indices)

    list_of_chunks = []
    for n in range(nchunks):
        steps_list_chunk = steplist[chunk_start_indices[n]:chunk_start_indices[n]+delta_chunk_indices]
        #if we're on the last chunk, we might not have the full list included, so need to make sure that we have that here
        if n == nchunks-1:
            steps_list_chunk = steplist[chunk_start_indices[n]::]
        list_of_chunks.append(steps_list_chunk)

    for arg in list_of_chunks:
        fhs.FindHaloStars(arg)
        
    # fhs.FindHaloStars(list_of_chunks[0])  # Useful for checking work on single snapshot
                                            #    before multiprocessing. Replaces next four lines of code

    '''
    p.map(fhs.FindHaloStars, [arg for arg in list_of_chunks])

    p.close()
    p.terminate()
    p.join()
    '''

        
if __name__ == '__main__':
    n_processes = 4 # default number of processes 

    if len(sys.argv)<3 or len(sys.argv)>4:
        print ('Usage: python LocAtCreation_pool_rz.py <sim> opt:<nproc>')
        print ('       default number of processes is '+int(n_processes))
        sys.exit()
    elif len(sys.argv)==3:
        simpath = str(sys.argv[1])
        odir = str(sys.argv[2])
    else:
        simpath = str(sys.argv[1])
        odir = str(sys.argv[2])
        n_processes = int(sys.argv[3])

    main(sim_path, odir, n_processes)
        
'''
Created on Mar 4, 2024

@author: anna
'''
